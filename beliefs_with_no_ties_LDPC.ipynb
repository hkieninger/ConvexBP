{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ziel ist zu beobachten: not MAP <=> ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(4589)\n",
    "# np.seterr(all=\"raise\")\n",
    "np.seterr(all=\"warn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import snippets\n",
    "import BeliefPropagation\n",
    "import BinaryBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cws = 1000\n",
    "EbN0 = 2\n",
    "max_iters = 600\n",
    "code = snippets.n7k4_hamming\n",
    "\n",
    "rx = snippets.simulateAWGNChannelTransmission(code, EbN0, num_cws)\n",
    "#bp = BeliefPropagation.BeliefPropagation(code.adjacency_matrix(), 2)\n",
    "bp = BinaryBP.BinaryBP(code.adjacency_matrix())\n",
    "gamma = bp.gammaDefaultCBP()\n",
    "c_var = bp.c_var_DefaultCBP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute MPA assignment for converged cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BinaryBP.py:135: RuntimeWarning: divide by zero encountered in log\n",
      "  llr_message_generator = self.llr_belief_propagation(np.log(factors), max_product, gamma, temperature, damping)\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BinaryBP.py:124: RuntimeWarning: overflow encountered in exp\n",
      "  lr = np.exp(llr)\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BinaryBP.py:124: RuntimeWarning: underflow encountered in exp\n",
      "  lr = np.exp(llr)\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BinaryBP.py:127: RuntimeWarning: underflow encountered in divide\n",
      "  lin[:,:,1] = 1 / (1 + lr)\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BinaryBP.py:131: RuntimeWarning: underflow encountered in divide\n",
      "  lin /= np.max(lin,axis=2,keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.1% converged (971/1000)\n"
     ]
    }
   ],
   "source": [
    "var_beliefs = np.empty((*rx.shape, 2))\n",
    "check_beliefs = np.empty((num_cws, bp.m) + bp.df_max * (2,))\n",
    "iterations = np.empty(var_beliefs.shape[0])\n",
    "for cw_idx in range(var_beliefs.shape[0]):\n",
    "    (var_beliefs[cw_idx,:], check_beliefs[cw_idx,:], _, iterations[cw_idx]) = bp.run_belief_propagation(\n",
    "        max_iters=max_iters,\n",
    "        convergence_threshold=1e-12,\n",
    "        factors=code.factors_AWGN(rx[cw_idx], EbN0),\n",
    "        max_product=True,\n",
    "        gamma=gamma,\n",
    "        damping=0.5\n",
    "    )\n",
    "converged = iterations < max_iters\n",
    "converged_cnt = np.sum(converged)\n",
    "print(f\"{converged_cnt / num_cws * 100}% converged ({converged_cnt}/{num_cws})\")\n",
    "mpa_assignment = np.argmax(var_beliefs[converged,:], axis=2) # decode with beliefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute MAP assignment for converged cases and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPA unequal MAP 2.368692070030896 % (23/971)\n"
     ]
    }
   ],
   "source": [
    "map_assignment = snippets.bruteforce_blockwiseMAP_AWGNChannel(code, rx[converged,:])\n",
    "mpa_unequal_map = np.sum(np.logical_xor(mpa_assignment, map_assignment), axis=1) > 0\n",
    "mpa_unequal_map_cnt = np.sum(mpa_unequal_map)\n",
    "print(f\"MPA unequal MAP {mpa_unequal_map_cnt / converged_cnt * 100} % ({mpa_unequal_map_cnt}/{converged_cnt})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6239/3079852416.py:1: RuntimeWarning: divide by zero encountered in divide\n",
      "  min_abs_llr = np.min(np.abs(np.log(var_beliefs[converged][:,:,0] / var_beliefs[converged][:,:,1])), axis=1)\n",
      "/tmp/ipykernel_6239/3079852416.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  min_abs_llr = np.min(np.abs(np.log(var_beliefs[converged][:,:,0] / var_beliefs[converged][:,:,1])), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unequal LLR maximum: 10.92776703875542 / equal LLR minimum: 0.05224372269064965\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_abs_llr = np.min(np.abs(np.log(var_beliefs[converged][:,:,0] / var_beliefs[converged][:,:,1])), axis=1)\n",
    "\n",
    "unequal_llrs = min_abs_llr[mpa_unequal_map]\n",
    "equal_llrs = min_abs_llr[np.logical_not(mpa_unequal_map)]\n",
    "print(f\"unequal LLR maximum: {np.max(unequal_llrs)} / equal LLR minimum: {np.min(equal_llrs)}\")\n",
    "\n",
    "hist_max = np.max(unequal_llrs[unequal_llrs < float('inf')]) + np.average(equal_llrs[equal_llrs < float('inf')])\n",
    "bins = np.linspace(0, hist_max, 20)\n",
    "plt.hist(unequal_llrs, bins, alpha=0.5, label=\"unequal\", log=True)\n",
    "plt.hist(equal_llrs, bins, alpha=0.5, label=\"equal\", log=True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:227: RuntimeWarning: divide by zero encountered in power\n",
      "  probability_distribution_marginals *= (variable_beliefs[variable]**c_var[variable]).reshape(shape)\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:227: RuntimeWarning: invalid value encountered in multiply\n",
      "  probability_distribution_marginals *= (variable_beliefs[variable]**c_var[variable]).reshape(shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "marginalisation_constraint = np.zeros(converged_cnt)\n",
    "admissibility_constraint = np.zeros(converged_cnt)\n",
    "for cw in range(converged_cnt):\n",
    "    marginalisation_constraint[cw] = bp.satisfyMarginalization(var_beliefs[converged][cw], check_beliefs[converged][cw], max=True, atol=1e-4)\n",
    "    admissibility_constraint[cw] = bp.satisfyAdmissibility(var_beliefs[converged][cw], check_beliefs[converged][cw], c_var, code.factors_AWGN(rx[cw], EbN0), atol=1e-3)\n",
    "\n",
    "print(marginalisation_constraint)\n",
    "print(admissibility_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
