{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is the implement the Spin-Glass Modell of Weiss (Chapter 6) with SPA instead of MPA\n",
    "we want to observe what the numerical issues are with setting T=0\n",
    "-> issue is that we get division by zero during message updates, (gamma - 1) can be negative and message at same time 0 (-inf in log domain)\n",
    "   so that message update containing message^(gamma - 1) can't be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import LogBeliefPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(4589)\n",
    "# np.seterr(all=\"raise\")\n",
    "np.seterr(all=\"warn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 100\n",
    "max_iters = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree1_adjacency = np.eye(9, dtype=int)\n",
    "degree2_adjacency = np.array([\n",
    "    [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "\n",
    "    [1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
    "], dtype=int)\n",
    "adjacency_matrix = np.concatenate((degree1_adjacency, degree2_adjacency), dtype=int)\n",
    "\n",
    "degree1_factors = np.random.randn(num_models, 9).reshape(num_models, 9, 1, 1) * -0.4 * np.array([[1, 1], [-1, -1]]).reshape(1, 1, 2, 2) # shape (num_models, 9, 2, 2)\n",
    "degree2_factors = np.random.randn(num_models, 12).reshape(num_models, 12, 1, 1) * -1.0 * np.array([[1, -1], [-1, 1]]).reshape(1, 1, 2, 2)\n",
    "log_factors = np.array([np.concatenate((degree1_factors[model_idx], degree2_factors[model_idx]), axis=0) for model_idx in range(num_models)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 21, 2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25365/3785610350.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  log_factors = np.log((log_factors == 0).astype(dtype=float))\n"
     ]
    }
   ],
   "source": [
    "# do ^1/T with T->0 and normalize\n",
    "print(log_factors.shape)\n",
    "log_factors -= np.max(log_factors, axis=tuple(list(range(2,4))), keepdims=True)\n",
    "log_factors = np.log((log_factors == 0).astype(dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.  -2.5 -2.  -2.5 -3.  -2.5 -2.  -2.5 -2. ]\n",
      "[1.         1.14285714 1.         1.14285714 1.25       1.14285714\n",
      " 1.         1.14285714 1.        ]\n",
      "[1.         0.88888889 1.         0.88888889 0.83333333 0.88888889\n",
      " 1.         0.88888889 1.        ]\n",
      "[0.75       0.88888889 0.75       0.88888889 1.         0.88888889\n",
      " 0.75       0.88888889 0.75      ]\n"
     ]
    }
   ],
   "source": [
    "bp = LogBeliefPropagation.LogBeliefPropagation(adjacency_matrix, state_domain_size=2)\n",
    "c_var = bp.c_var_DefaultCBP()\n",
    "print(c_var)\n",
    "gamma = bp.gammaDefaultCBP()\n",
    "print(gamma)\n",
    "gamma = bp.dv / (2 * bp.dv - 1 + c_var)\n",
    "print(gamma)\n",
    "print(bp.dv / (2 - c_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20eca401e4314466a6baa1a79030f5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/LogBeliefPropagation.py:59: RuntimeWarning: divide by zero encountered in log\n",
      "  f2v0_fview[:,extrinsic_port,:] = np.log(np.sum(np.exp(accumulator), axis=axes))\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/LogBeliefPropagation.py:79: RuntimeWarning: invalid value encountered in subtract\n",
      "  v2f -= np.max(v2f, axis=2, keepdims=True)\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/LogBeliefPropagation.py:59: RuntimeWarning: divide by zero encountered in log\n",
      "  f2v0_fview[:,extrinsic_port,:] = np.log(np.sum(np.exp(accumulator), axis=axes))\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/LogBeliefPropagation.py:78: RuntimeWarning: invalid value encountered in subtract\n",
      "  f2v -= np.max(f2v, axis=2, keepdims=True)\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/LogBeliefPropagation.py:71: RuntimeWarning: invalid value encountered in add\n",
      "  f2v = (f2v0_vview * shaped_gamma + v2f0_vview_masked * (shaped_gamma - 1)) * (1 - damping) + f2v * damping\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/LogBeliefPropagation.py:75: RuntimeWarning: invalid value encountered in add\n",
      "  v2f = (v2f0_vview * shaped_gamma + f2v0_vview_masked * (shaped_gamma - 1)) * (1 - damping) + v2f * damping\n"
     ]
    }
   ],
   "source": [
    "var_beliefs = np.empty((num_models, 9, 2))\n",
    "check_beliefs = np.empty((num_models, bp.m) + bp.df_max * (2,))\n",
    "iterations = np.empty(var_beliefs.shape[0])\n",
    "\n",
    "progress_bar = IntProgress(min=0, max=num_models)\n",
    "display(progress_bar)\n",
    "\n",
    "for cw_idx in range(var_beliefs.shape[0]):\n",
    "    progress_bar.value = cw_idx\n",
    "    (var_beliefs[cw_idx,:], check_beliefs[cw_idx,:], iterations[cw_idx]) = bp.run_log_belief_propagation(\n",
    "        max_iters=max_iters,\n",
    "        rtol=1e-5,\n",
    "        atol=1e-8,\n",
    "        infty=1e10,\n",
    "        log_factors=log_factors[cw_idx],\n",
    "        temperature=1,\n",
    "        max_product=False,\n",
    "        gamma=gamma,\n",
    "        damping=0.5\n",
    "    )\n",
    "converged = iterations < max_iters\n",
    "converged_cnt = np.sum(converged)\n",
    "print(f\"{converged_cnt / num_models * 100}% converged ({converged_cnt}/{num_models})\")\n",
    "mpa_assignment = np.argmax(var_beliefs, axis=2) # decode with beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPA unequal MAP nan % (0/0)\n",
      "converged and unequal nan % (0/0)\n",
      "converged and equal nan % (0/0)\n",
      "not converged and unequal 0.0 % (0/100)\n",
      "not converged and equal 100.0 % (100/100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25365/2963908489.py:4: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print(f\"MPA unequal MAP {mpa_unequal_map_cnt / converged_cnt * 100} % ({mpa_unequal_map_cnt}/{converged_cnt})\")\n",
      "/tmp/ipykernel_25365/2963908489.py:9: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print(f\"converged and unequal {converged_unequal_cnt / converged_cnt * 100} % ({converged_unequal_cnt}/{converged_cnt})\")\n",
      "/tmp/ipykernel_25365/2963908489.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print(f\"converged and equal {converged_equal_cnt / converged_cnt * 100} % ({converged_equal_cnt}/{converged_cnt})\")\n"
     ]
    }
   ],
   "source": [
    "map_assignment = bp.bruteforce_MAP(log_factors)\n",
    "mpa_unequal_map = np.sum(np.logical_xor(mpa_assignment, map_assignment), axis=1) > 0\n",
    "mpa_unequal_map_cnt = np.sum(mpa_unequal_map)\n",
    "print(f\"MPA unequal MAP {mpa_unequal_map_cnt / converged_cnt * 100} % ({mpa_unequal_map_cnt}/{converged_cnt})\")\n",
    "\n",
    "# divide into 4 cases\n",
    "converged_unequal = np.logical_and(converged, mpa_unequal_map)\n",
    "converged_unequal_cnt = np.sum(converged_unequal)\n",
    "print(f\"converged and unequal {converged_unequal_cnt / converged_cnt * 100} % ({converged_unequal_cnt}/{converged_cnt})\")\n",
    "converged_equal = np.logical_and(converged, np.logical_not(mpa_unequal_map))\n",
    "converged_equal_cnt = np.sum(converged_equal)\n",
    "print(f\"converged and equal {converged_equal_cnt / converged_cnt * 100} % ({converged_equal_cnt}/{converged_cnt})\")\n",
    "notconverged_unequal = np.logical_and(np.logical_not(converged), mpa_unequal_map)\n",
    "notconverged_unequal_cnt = np.sum(notconverged_unequal)\n",
    "print(f\"not converged and unequal {notconverged_unequal_cnt / (num_models - converged_cnt) * 100} % ({notconverged_unequal_cnt}/{num_models - converged_cnt})\")\n",
    "notconverged_equal = np.logical_and(np.logical_not(converged), np.logical_not(mpa_unequal_map))\n",
    "notconverged_equal_cnt = np.sum(notconverged_equal)\n",
    "print(f\"not converged and equal {notconverged_equal_cnt / (num_models - converged_cnt) * 100} % ({notconverged_equal_cnt}/{num_models - converged_cnt})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "all LLRs are infinite, plotting historgramm doesn't make sense",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25365/686583693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfinite_llrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_abs_llr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_abs_llr\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinite_llrs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all LLRs are infinite, plotting historgramm doesn't make sense\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmax_finite_llr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinite_llrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmin_abs_llr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_abs_llr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_finite_llr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: all LLRs are infinite, plotting historgramm doesn't make sense"
     ]
    }
   ],
   "source": [
    "min_abs_llr = np.min(np.abs(var_beliefs[:,:,0] - var_beliefs[:,:,1]), axis=1)\n",
    "\n",
    "finite_llrs = min_abs_llr[min_abs_llr < float('inf')]\n",
    "if len(finite_llrs) == 0:\n",
    "    raise Exception(\"all LLRs are infinite, plotting historgramm doesn't make sense\")\n",
    "max_finite_llr = np.max(finite_llrs)\n",
    "min_abs_llr[min_abs_llr == float('inf')] = max_finite_llr\n",
    "bins = np.linspace(0, max_finite_llr + 1, 20)\n",
    "\n",
    "if converged_unequal_cnt > 0:\n",
    "    print(f\"converged unequal maximum min(abs(llr)): {np.max(min_abs_llr[converged_unequal])}\")\n",
    "    plt.hist(min_abs_llr[converged_unequal], bins, alpha=0.5, label=\"converged unequal\", log=True)\n",
    "if converged_equal_cnt > 0:\n",
    "    print(f\"converged equal minimum min(abs(llr)): {np.min(min_abs_llr[converged_equal])}\")\n",
    "    plt.hist(min_abs_llr[converged_equal], bins, alpha=0.5, label=\"converged equal\", log=True)\n",
    "if notconverged_unequal_cnt > 0:\n",
    "    print(f\"not converged unequal maximum min(abs(llr)): {np.max(min_abs_llr[notconverged_unequal])}\")\n",
    "    plt.hist(min_abs_llr[notconverged_unequal], bins, alpha=0.5, label=\"not convreged unequal\", log=True)\n",
    "if notconverged_equal_cnt > 0:\n",
    "    print(f\"not converged equal minimum min(abs(llr)): {np.min(min_abs_llr[notconverged_equal])}\")\n",
    "    plt.hist(min_abs_llr[notconverged_equal], bins, alpha=0.5, label=\"not converged equal\", log=True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
