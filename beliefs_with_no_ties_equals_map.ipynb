{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ziel ist zu beobachten: not MAP <=> ties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'warn', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(4589)\n",
    "# np.seterr(all=\"raise\")\n",
    "np.seterr(all=\"warn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snippets\n",
    "import BeliefPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cws = 1000\n",
    "EbN0 = 2\n",
    "max_iters = 200\n",
    "code = snippets.n7k4_hamming\n",
    "\n",
    "rx = snippets.simulateAWGNChannelTransmission(code, EbN0, num_cws)\n",
    "bp = BeliefPropagation.BeliefPropagation(code.adjacency_matrix(), 2)\n",
    "gamma = bp.gammaTrivialCBP()\n",
    "c_var = bp.c_var_TrivialCBP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute MPA assignment for converged cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:111: RuntimeWarning: underflow encountered in power\n",
      "  for extrinsic_port in range(self.dv_max):\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:111: RuntimeWarning: underflow encountered in multiply\n",
      "  for extrinsic_port in range(self.dv_max):\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:113: RuntimeWarning: underflow encountered in power\n",
      "  v2f0_vview[np.logical_not(self.v_mask)] = 1\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:101: RuntimeWarning: underflow encountered in multiply\n",
      "  for extrinsic_port in range(self.df_max):\n",
      "/home/hans/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: underflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:113: RuntimeWarning: underflow encountered in multiply\n",
      "  v2f0_vview[np.logical_not(self.v_mask)] = 1\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  f2v = (f2v0_vview**shaped_gamma * v2f0_vview**(shaped_gamma-1))**(1-damping) * f2v**damping\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:117: RuntimeWarning: invalid value encountered in divide\n",
      "  # variable node update\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:117: RuntimeWarning: underflow encountered in divide\n",
      "  # variable node update\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:141: RuntimeWarning: underflow encountered in multiply\n",
      "  # compute factor beliefs\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:143: RuntimeWarning: underflow encountered in divide\n",
      "  v2f_fview[self.f_mask] = v2f[self.v_mask,:][self.v2f_reshape,:]\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:116: RuntimeWarning: underflow encountered in divide\n",
      "  f2v = (f2v0_vview**shaped_gamma * v2f0_vview**(shaped_gamma-1))**(1-damping) * f2v**damping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0% converged (950/1000)\n"
     ]
    }
   ],
   "source": [
    "var_beliefs = np.empty((*rx.shape, 2))\n",
    "check_beliefs = np.empty((num_cws, bp.m) + bp.df_max * (2,))\n",
    "iterations = np.empty(var_beliefs.shape[0])\n",
    "for cw_idx in range(var_beliefs.shape[0]):\n",
    "    (var_beliefs[cw_idx,:], check_beliefs[cw_idx,:], _, iterations[cw_idx]) = bp.run_belief_propagation(\n",
    "        max_iters=max_iters,\n",
    "        convergence_threshold=1e-6,\n",
    "        factors=code.factors_AWGN(rx[cw_idx], EbN0),\n",
    "        max_product=True,\n",
    "        gamma=gamma,\n",
    "        damping=0\n",
    "    )\n",
    "converged = iterations < max_iters\n",
    "converged_cnt = np.sum(converged)\n",
    "print(f\"{converged_cnt / num_cws * 100}% converged ({converged_cnt}/{num_cws})\")\n",
    "mpa_assignment = np.argmax(var_beliefs[converged,:], axis=2) # decode with beliefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute MAP assignment for converged cases and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPA unequal MAP 16.42105263157895 % (156/950)\n"
     ]
    }
   ],
   "source": [
    "map_assignment = snippets.bruteforce_blockwiseMAP_AWGNChannel(code, rx[converged,:])\n",
    "mpa_unequal_map = np.sum(np.logical_xor(mpa_assignment, map_assignment), axis=1) > 0\n",
    "mpa_unequal_map_cnt = np.sum(mpa_unequal_map)\n",
    "print(f\"MPA unequal MAP {mpa_unequal_map_cnt / converged_cnt * 100} % ({mpa_unequal_map_cnt}/{converged_cnt})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unequal LLR maximum: inf / equal LLR minimum: 117.27827880074754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22716/2786033868.py:1: RuntimeWarning: divide by zero encountered in divide\n",
      "  min_abs_llr = np.min(np.abs(np.log(var_beliefs[:,:,0] / var_beliefs[:,:,1])), axis=1)\n",
      "/tmp/ipykernel_22716/2786033868.py:1: RuntimeWarning: overflow encountered in divide\n",
      "  min_abs_llr = np.min(np.abs(np.log(var_beliefs[:,:,0] / var_beliefs[:,:,1])), axis=1)\n",
      "/tmp/ipykernel_22716/2786033868.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  min_abs_llr = np.min(np.abs(np.log(var_beliefs[:,:,0] / var_beliefs[:,:,1])), axis=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_abs_llr = np.min(np.abs(np.log(var_beliefs[converged][:,:,0] / var_beliefs[converged][:,:,1])), axis=1)\n",
    "\n",
    "unequal_llrs = min_abs_llr[mpa_unequal_map]\n",
    "equal_llrs = min_abs_llr[np.logical_not(mpa_unequal_map)]\n",
    "print(f\"unequal LLR maximum: {np.max(unequal_llrs)} / equal LLR minimum: {np.min(equal_llrs)}\")\n",
    "\n",
    "hist_max = np.max(unequal_llrs[unequal_llrs < float('inf')]) + np.average(equal_llrs[equal_llrs < float('inf')])\n",
    "bins = np.linspace(0, hist_max, 20)\n",
    "plt.hist(unequal_llrs, bins, alpha=0.5, label=\"unequal\")\n",
    "plt.hist(equal_llrs, bins, alpha=0.5, label=\"equal\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:225: RuntimeWarning: underflow encountered in multiply\n",
      "  marginal = marginalisation_operator(factor_beliefs[factor], tuple(axes))\n",
      "/home/hans/Studium/Masterarbeit/Code/ConvexBP/BeliefPropagation.py:189: RuntimeWarning: underflow encountered in multiply\n",
      "  for factor in range(self.m):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "marginalisation_constraint = np.zeros(converged_cnt)\n",
    "admissibility_constraint = np.zeros(converged_cnt)\n",
    "for cw in range(converged_cnt):\n",
    "    marginalisation_constraint[cw] = bp.satisfyMarginalization(var_beliefs[converged][cw], check_beliefs[converged][cw], max=True, atol=1e-4)\n",
    "    admissibility_constraint[cw] = bp.satisfyAdmissibility(var_beliefs[converged][cw], check_beliefs[converged][cw], c_var, code.factors_AWGN(rx[cw], EbN0), atol=1e-3)\n",
    "\n",
    "print(marginalisation_constraint)\n",
    "print(admissibility_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
